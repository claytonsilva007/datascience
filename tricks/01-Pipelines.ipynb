{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PIPELINES - DEFINIÇÃO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definição: \r\n",
    "#### Pipelines são classes que permitem automatizar o fluxo de preparação dos dados durante projetos de Machine Learning. \r\n",
    "\r\n",
    "## 2. Por que devo utilizar pipelines?\r\n",
    "#### a) O processo de preparação dos dados em conjunto de treinamento, validação e testes pode ser custoso. Uma vez construído, o pipeline pode ser aplicado em todos os conjuntos de dados(treinamento, validação e testes);\r\n",
    "#### b) Permite-nos chamar uma única vez os métodos fit() e predict() para uma sequência de estimadores;\r\n",
    "#### c) Permite que executemos a otimização de parâmetros de todos os nossos estimadores dentro de um pipeline;\r\n",
    "#### d) Código mais limpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. OBTENDO OS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = '../datasets/train.csv'\r\n",
    "PATH_TEST = '../datasets/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\r\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train = load_dataset(PATH_TRAIN)\r\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                              Name     Sex   Age  SibSp  \\\n",
       "0          892       3                  Kelly, Mr. James    male  34.5      0   \n",
       "1          893       3  Wilkes, Mrs. James (Ellen Needs)  female  47.0      1   \n",
       "\n",
       "   Parch  Ticket    Fare Cabin Embarked  \n",
       "0      0  330911  7.8292   NaN        Q  \n",
       "1      0  363272  7.0000   NaN        S  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = load_dataset(PATH_TEST)\r\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CRIANDO PIPELINES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### settings fiels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Survived', 'Pclass', 'Age', 'Sex', 'SibSp', 'Parch', 'Fare', 'Embarked']\r\n",
    "\r\n",
    "numerical_labels = ['Age', 'Fare']\r\n",
    "categorical_labels = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "treino, validacao = train_test_split(train[labels], test_size=0.3)\r\n",
    "\r\n",
    "X_treino = treino.drop('Survived', axis=1)\r\n",
    "y_treino = treino['Survived']\r\n",
    "\r\n",
    "X_valid = validacao.drop(columns=['Survived'], axis=1)\r\n",
    "y_valid = validacao['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline para atributos numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline(steps=[\r\n",
    "    ('imp', SimpleImputer(strategy='median')),\r\n",
    "    ('scaler', StandardScaler())\r\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline para atributos categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe = Pipeline(steps=[\r\n",
    "    ('imp', SimpleImputer(strategy='most_frequent')),\r\n",
    "    ('ohe', OneHotEncoder())\r\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntando todos os pipelines em uma ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = ColumnTransformer(transformers=[\r\n",
    "    ('num_pipe', num_pipe, numerical_labels),\r\n",
    "    ('cat_pipe', cat_pipe, categorical_labels)\r\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PIPELINES E ESTIMADORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_models(model):\r\n",
    "\r\n",
    "   pipeline = Pipeline(steps=[\r\n",
    "      ('preprocess', preprocess),\r\n",
    "      ('classifier', model)\r\n",
    "   ])\r\n",
    "   \r\n",
    "   pipeline.fit(X_treino, y_treino)\r\n",
    "   y_predict = pipeline.predict(X_valid)\r\n",
    "   print(classification_report(y_valid, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       162\n",
      "           1       0.76      0.67      0.71       106\n",
      "\n",
      "    accuracy                           0.78       268\n",
      "   macro avg       0.78      0.76      0.77       268\n",
      "weighted avg       0.78      0.78      0.78       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       162\n",
      "           1       0.82      0.71      0.76       106\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.82      0.80      0.81       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "\r\n",
    "models = [RandomForestClassifier(), LogisticRegression()]\r\n",
    "\r\n",
    "for model in models:\r\n",
    "    cross_validate_models(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "457430c490b8ef621f5c81503a8a5d65e73d280039118beaa3879d8af43f0951"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0')",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}