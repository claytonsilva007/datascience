{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import seaborn as sns\r\n",
    "import sys\r\n",
    "import zipfile\r\n",
    "import os\r\n",
    "import matplotlib as ml\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "\r\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
    "\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, RandomTreesEmbedding\r\n",
    "from sklearn.linear_model import SGDClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "\r\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve, roc_curve, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = '../datasets/train.csv'\r\n",
    "PATH_TEST = '../datasets/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\r\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS AND HELPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pronouns(text):\r\n",
    "    if ', ' in text:\r\n",
    "        text = text.split(', ')[1]\r\n",
    "        return text.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_col_pronouns(dataframe):\r\n",
    "    dataframe['Pronouns'] = dataframe['Name'].apply(lambda x: find_pronouns(x))\r\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFORMING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATAFRAME PANDAS TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Survived', 'Age', 'Fare', 'Parch', 'Pclass', 'Sex', 'SibSp', 'Embarked']\r\n",
    "\r\n",
    "numerical_labels = ['Age', 'Fare']\r\n",
    "categorical_labels = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\r\n",
    "\r\n",
    "cols_to_drop = ['Name', 'Cabin', 'PassengerId', 'Ticket', 'Cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando transformador personalizado para dataframes pandas\r\n",
    "class DataFrameFunctionTransformer(BaseEstimator, TransformerMixin):\r\n",
    "    def __init__(self, func):\r\n",
    "        self.func = func\r\n",
    "    \r\n",
    "    def transform(self, input_df):\r\n",
    "        return self.func(input_df)\r\n",
    "\r\n",
    "    def fit(self, X, y=None):\r\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como a obtenção de amostras estratificadas não funciona se houver categorias com apenas uma instância, é necessário incluir essas instâncias\r\n",
    "# em uma classe chamada Another\r\n",
    "\r\n",
    "def adder_pronouns_cat(input_df):\r\n",
    "    input_df['Pronouns'] = input_df['Name'].apply(lambda x: find_pronouns(x))\r\n",
    "    s = input_df['Pronouns'].value_counts()\r\n",
    "    input_df['Pronouns'] = input_df['Pronouns'].apply(lambda x: 'another' if s[x]<=1 else x)\r\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(input_df):\r\n",
    "    input_df = input_df.drop(columns=cols_to_drop, axis=1)\r\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adder_pipe = Pipeline([ \r\n",
    "    ('create-column-pronoun-cat', DataFrameFunctionTransformer(adder_pronouns_cat))\r\n",
    "])\r\n",
    "\r\n",
    "drop_pipe = Pipeline([\r\n",
    "    ('drop-columns', DataFrameFunctionTransformer(drop_columns))\r\n",
    "])\r\n",
    "\r\n",
    "#transformer = ColumnTransformer([\r\n",
    "#    ('add', adder_pipe, train.columns.values),\r\n",
    "#    ('drop', drop_pipe, train.columns.values)\r\n",
    "#])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline(steps=[\r\n",
    "    ('imp', SimpleImputer(strategy='median')),\r\n",
    "    ('scaler', StandardScaler())\r\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe = Pipeline(steps=[\r\n",
    "    ('imp', SimpleImputer(strategy='most_frequent')),\r\n",
    "    ('ohe', OneHotEncoder())\r\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = ColumnTransformer(transformers=[\r\n",
    "    ('num', num_pipe, numerical_labels),\r\n",
    "    ('cat', cat_pipe, categorical_labels)\r\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROSS-VAL-SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o conjunto de dados em treinamento e teste\r\n",
    "\r\n",
    "train = load_dataset(path=PATH_TRAIN)\r\n",
    "test = load_dataset(path=PATH_TEST)\r\n",
    "\r\n",
    "treino, validacao = train_test_split(train[labels], test_size=0.3)\r\n",
    "\r\n",
    "X_treino = treino.drop('Survived', axis=1)\r\n",
    "y_treino = treino['Survived']\r\n",
    "\r\n",
    "X_valid = validacao.drop(columns=['Survived'], axis=1)\r\n",
    "y_valid = validacao['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [DecisionTreeClassifier(), RandomForestClassifier(), LogisticRegression(), SVC(), SGDClassifier(), KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cross_validate(model):\r\n",
    "   estimator = make_pipeline(preprocess, model)\r\n",
    "   scores = cross_val_score(estimator, X_treino, y_treino, cv=5, scoring=\"accuracy\")\r\n",
    "   print(\"Model Name: \", type(model).__name__)\r\n",
    "   print(scores.mean())\r\n",
    "   print(\"--------------------------------------------------------------------------\")\r\n",
    "\r\n",
    "#for model in models:\r\n",
    "   #display_cross_validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_stats(model):\r\n",
    "    estimator = make_pipeline(preprocess, model)\r\n",
    "    estimator.fit(X_treino, y_treino)\r\n",
    "    y_predict = estimator.predict(X_valid)\r\n",
    "    \r\n",
    "    print(\"Model Name: \", type(model).__name__)\r\n",
    "    print(classification_report(y_valid, y_predict))\r\n",
    "    print(\"--------------------------------------------------------------------------\")\r\n",
    "\r\n",
    "for model in models:\r\n",
    "    display_stats(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "457430c490b8ef621f5c81503a8a5d65e73d280039118beaa3879d8af43f0951"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}